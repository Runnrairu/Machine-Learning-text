\documentclass{jsarticle}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{type1cm}
\usepackage{bm}
\usepackage{here}
\usepackage{mathrsfs}
\usepackage[margin=2cm]{geometry}
\usepackage{wrapfig}
\usepackage[dvipdfmx]{hyperref}
\usepackage{pxjahyper}
\usepackage{comment}

\renewcommand{\refname}{参考文献}
\newtheorem{theo}{定理}
\newtheorem{ho}{補題}
\newtheorem{defi}{定義}

\begin{document}

\begin{center}
  
  \Huge Github版 \par
  \vspace{15mm}
  \Huge 一般的\footnote{ここで言う「一般的な」とは、「普通の人にもわかりやすい」という意味ではなく、数学界隈における「汎用性の高い」「広く対応可能な定義を導入している」という意味である。}な機械学習入門\par
  \vspace{90mm}
  \Large 最終更新：2020年10月11日 \par
  \Large 逢空れい@ranoiaru\par

\end{center}
\thispagestyle{empty}
\clearpage
\addtocounter{page}{-1}







\newpage


 \tableofcontents
 \clearpage
\section*{notation}
\begin{itemize}
\item $\mathcal{X}$：特徴量空間。$\mathbb{R}^d$の単連結な開部分集合
\item $\mathcal{Y}$：ラベル空間。$\mathbb{R}^n$もしくは$\mathbb{C}^n$
\item $(\Omega,\mathcal{F},P)$：確率空間
\item $H$：使う手法により異なる条件を満たす関数$f:\mathcal{X}\to\mathcal{Y}$の集合が為す可分ヒルベルト空間
\item $L$：頻度論的手法における損失関数$H\times\Omega \to \mathbb{R}$

\item $\mathcal{P}((\Omega,\mathcal{F})$：可測空間$(\Omega,\mathcal{F})$上の確率測度全体の集合。$\mathcal{F}$を略記し、$\Omega$が距離空間である場合、$\mathcal{P}(\Omega)$は$\mathcal{P}((\Omega,\mathcal{B}(\Omega))$であるものとする。
\item $\mathcal{R}$：リッジレット作用素
\item $\mathcal{R}^*$:双対リッジレット作用素
\item $D_{ucp}$：ucp位相の入ったc\'{a}dl\'{a}gな適合過程の集合。（すなわち発展的可測）
\item $L_{ucp}$：同上。ただし上が確率積分の定義域であるのに対して、こちらは値域。確率過程として動いている空間が違ったりする。
\item $N$：ポアソンランダム測度
\end{itemize}


\newpage
\section{はじめに}

深夜テンションによる出来心で「数学徒向けの機械学習入門書を書いたら見てくれる人ふぁぼください。ふぁぼ多かったら実行します」と書いたら、なんか一晩で500以上ふぁぼられたうえ、なぜか200近くフォロワーが増えたのでやらざるを得ない。

\subsection{本書執筆の経緯（よまなくてもいいよ）}
本書の構想は三年前に遡る。当時私は機械学習に入門したばかりの修士課程学生だったが、その時に触れた書籍があまりに数学的厳密性にも一般性にも欠け、そのことに対する苛立ちをツイートにぶつけた。

その結果、燃えた。

クソリプと暴言の嵐で通知が埋まり、私はしばらく鍵垢に籠った。

私の言い方も大いに悪かったのだが、あまりにも曲解されすぎではないかと当時の私は思ったものである。あの発言の意図としては、インターン時のパワハラ面接官や、twitterのひたすらマウントをとってくる某エンジニアに対して「数学ろくに知らないくせに『数学なんて機械学習に無意味』なんていうんじゃない」ということであり、断じて「純粋数学に明るくなきゃ本当に機械学習わかってるとは言えない」などということではない。誓ってもいい。

その時私は、数学徒向けの機械学習入門理論を整備すると宣言し、実際に修論にはそれを書いたり、数学徒のつどいで講演したりしたのだが、このように資料の形での公開はほとんどしていない。

機械学習界隈を騒がせてからちょうど三年。私も学生時代が終わり、数学寄りの機械学習研究者として仕事をしながら、修士時代の研究室へ社会人博士への入学をもくろむ日々。ツイートがバズったのもなにかの縁であろう。変な書き方のせいで不快な思いをさせてしまった方々へのお詫びも兼ねて、ここはひとつ、数学徒向け機械学習入門書の執筆を行うことにした。

\subsection{前提知識}
本資料において、入門編の前提知識は「学部レベルの解析学」（主に関数解析とルベーグ積分）、発展編はその都度必要な知識を補完されたし。

確率解析は基本的に[1]の流儀を使用する。\footnote{数か月前まで無駄に難解なだけの読みにくい本だと思っていましたが、変な確率過程の研究をしだすとこんなにありがたい既存理論は他にないと分かります。この本がなかったら、私がここ４か月で出したの成果と同じ研究成果を出すのに３年くらいかかってそう。「ucp位相の入った適合c\'{a}dl\'{a}g過程空間」の確率解析理論がそこそこ完成されてる事実があまりに便利すぎる。}


\newpage

\section{入門：機械学習の一般的問題設定}

この章では、機械学習の問題設定について、関数解析的に定義する。

\begin{defi} データの定義

多数の特徴量とラベルの組、$\{(x_i,y_i)\}_i\subset \mathcal{X}\times \mathcal{Y}$をデータと呼ぶ。

\end{defi}

\subsection{頻度論的機械学習問題の定義}



\subsubsection{仮説空間}

特徴量空間からラベル空間への写像のうち、手法によってことなる条件を満たすものが為す可分ヒルベルト空間$H$を仮説空間と呼ぶ。この$H$の中から、なるべく良い$f$を選ぶのが、機械学習問題の目的である。



\subsubsection{損失関数}


次の定理は関数解析的定義と、実際のアルゴリズムを結ぶ超重要定理である。

\subsection{ベイズ論的機械学習問題の定義}





\newpage
\begin{thebibliography}{99}
  \bibitem{キー}  P. Protter, Stochastic Integration and Differential Equations, Applications of Mathematics, Second edition, Vol. 21 (Springer-Verlag, Berlin, 2005).
\end{thebibliography}

\end{document}
