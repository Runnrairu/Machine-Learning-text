\documentclass{jsarticle}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{type1cm}
\usepackage{bm}
\usepackage{here}
\usepackage{mathrsfs}
\usepackage[margin=2cm]{geometry}
\usepackage{wrapfig}
\usepackage[dvipdfmx]{hyperref}
\usepackage{pxjahyper}
\usepackage{ascmac}
\usepackage{comment}
\makeatletter
\renewcommand{\theequation}{%
\thesection.\arabic{equation}}
\@addtoreset{equation}{section}
\makeatother
\renewcommand{\refname}{参考文献}
\newtheorem{theo}{定理}[section]
\newtheorem{ho}{補題}[section]
\newtheorem{defi}{定義}[section]
\newtheorem{pro}{問}[section]
\newtheorem{cau}{問}[section]

\begin{document}

\begin{center}
  
  \Huge Github版 \par
  \vspace{15mm}
  \Huge 一般的な機械学習入門\par
  \vspace{90mm}
  \Large 最終更新：2021年5月21日 \par
  \Large 逢空れい@ririnarua\par

\end{center}
\thispagestyle{empty}
\clearpage
\addtocounter{page}{-1}







\newpage


 \tableofcontents
 \clearpage
\section*{notation}
\begin{itemize}
\item $\mathcal{X}$：特徴量空間。$\mathbb{R}^d$の単連結な開部分集合
\item $\mathcal{Y}$：ラベル空間。$\mathbb{R}^n$もしくは$\mathbb{C}^n$か、それらの上での確率測度の集合
\item $(\Omega,\mathcal{F},P)$：確率空間
\item $H$：使う手法により異なる条件を満たす関数$f:\mathcal{X}\to\mathcal{Y}$の集合が為す可分ヒルベルト空間
\item $L$：頻度論的手法における損失関数$H\times\Omega \to \mathbb{R}$
\item $\nabla_f L(f,\omega),f\in H$：頻度論的手法における勾配の定義。$\omega$を固定した上でのフレシェ微分に$f$を代入したもの。
\item $\mathcal{B}(A),A$は距離空間：ボレル集合族
\item $\mathcal{P}((\Omega,\mathcal{F})$：可測空間$(\Omega,\mathcal{F})$上の確率測度全体の集合。$\mathcal{F}$を略記し、$\Omega$が距離空間である場合、$\mathcal{P}(\Omega)$は$\mathcal{P}((\Omega,\mathcal{B}(\Omega))$であるものとする。
\item $\mathcal{R}$：リッジレット作用素
\item $\mathcal{R}^*$:双対リッジレット作用素
\item $D_{ucp}$：ucp位相の入ったc\'{a}dl\'{a}gな適合過程の集合。（すなわち発展的可測）
\item $L_{ucp}$：同上。ただし上が確率積分の定義域であるのに対して、こちらは値域。確率過程として動いている空間が違ったりする。
\item $N$：ポアソンランダム測度
\end{itemize}


\newpage
\section{はじめに}

深夜テンションによる出来心で「数学徒向けの機械学習入門書を書いたら見てくれる人ふぁぼください。ふぁぼ多かったら実行します」と書いたら、なんか一晩で500以上ふぁぼられたうえ、なぜか200近くフォロワーが増えたのでやらざるを得ない。

\subsection{本書執筆の経緯（よまなくてもいいよ）}

ここで言う「一般的な」とは、「普通の人にもわかりやすい」という意味ではなく、数学界隈における「汎用性の高い」「広く対応可能な定義を導入している」という意味である。

本書の構想は三年前に遡る。当時私は機械学習に入門したばかりの修士課程学生だったが、その時に触れた書籍があまりに数学的厳密性にも一般性にも欠け、そのことに対する苛立ちをツイートにぶつけた。

その結果、燃えた。

通知が埋まり、私はしばらく鍵垢に籠った。

私の言い方も大いに悪かったのだが、あまりにも曲解されすぎではないかと当時の私は思ったものである。あの発言の意図としては、インターン時のパワハラ面接官や、twitterのひたすらマウントをとってくる某エンジニアに対して「数学ろくに知らないくせに『数学なんて機械学習に無意味』なんていうんじゃない」ということであり、断じて「純粋数学に明るくなきゃ本当に機械学習わかってるとは言えない」などということではない。誓ってもいい。

その時私は、数学徒向けの機械学習入門理論を整備すると宣言し、実際に修論にはそれを書いたり、数学徒のつどいで講演したりしたのだが、このように資料の形での公開はほとんどしていない。

機械学習界隈を騒がせてからちょうど三年。私も学生時代が終わり、数学寄りの機械学習研究者として仕事をしながら、修士時代の研究室へ社会人博士への入学をもくろむ日々。ツイートがバズったのもなにかの縁であろう。変な書き方のせいで不快な思いをさせてしまった方々へのお詫びも兼ねて、ここはひとつ、数学徒向け機械学習入門書の執筆を行うことにした。

(2020/10/12)

\subsection{前提知識}
本資料において、入門編の前提知識は「学部レベルの解析学」（主に関数解析とルベーグ積分,
確率論）、発展編はその都度必要な知識を補完されたし。

確率解析は基本的に[1]の流儀を使用する。\footnote{数か月前まで無駄に難解なだけの読みにくい本だと思っていましたが、変な確率過程の研究をしだすとこんなにありがたい既存理論は他にないと分かります。この本がなかったら、私がここ４か月で出したの成果と同じ研究成果を出すのに３年くらいかかってそう。「ucp位相の入った適合c\'{a}dl\'{a}g過程空間」の確率解析理論がそこそこ完成されてる事実があまりに便利すぎる。}

\subsection{無料版と有料版}
後に本書はbooth等で販売する予定です。有料版は論文公開直後の最先端研究の解説や、確率論・統計学の基礎からマリアヴァン解析まで数学の簡易的な解説も付属します。投げ銭感覚でもいいので買ってくださると非常にありがたいです。価格は1万円未満にはします。

また、有料版発売後、githubで公開しているこの無料版は、よほどのミスや重大な数学的誤り以外修正しないので、ご了承ください。有料版は発見次第なるべく早く修正します。\footnote{boothは一度購入すれば制限なく新バージョン落とせます。}

\subsection{5月アップデートについて}
本日、大幅なアップデートを施した。更新が遅れて申し訳ありません。

ここ半年と一か月、私の人生を激変させる出来事が立て続けに起き、二度と私が私として浮上することができない可能性まであったため、とてもじゃないですが本書の更新をしてくことができませんでした。

ですが当時に比べればかなり元気になりましたし、高卒認定試験のツイートでフォロワーが大幅に増えたため、今こそVtuber計画を始動し、本の続きも書くべきだと考えて、一念発起してかなり文章を書きました。

先輩数学系Vtuberさんはみんな声が男なので、その辺で差別化していけたらなと思います。（媚びるのを隠さないスタイル）

(2021.5.12)

\subsection{5月下旬アップデートについて}

ポケモンのランクマでメインロムが死んだので腹いせに4章を更新することにしました。増田はもっとまともなエンジニアを雇うべきです。

メスガキVtuberと学術系Vtuberはどちらもたくさんいますが、「学術系メスガキVtuber」というのは新しいのではないでしょうか。通常のM1の講義で習う程度の数学は普通に教えて、マリアヴァン解析やFunctional Ito calculusやその他先端研究のような高等概念はメスガキキャラで講座をするという方針を考えています。

マリアヴァン解析でぶんなぐってくるメスガキがいてもいいと思う。

「オタク君たちがぁ$\heartsuit$私の論文を引用するたんびにスカートが1mm短くなりますよ～$\heartsuit$ま、あたまよわよわ$\heartsuit$なオタク君には理解すらできないだろうけど$\heartsuit$ざぁーこ$\heartsuit$ざぁーこ$\heartsuit$」という形でのメスガキ引用数ハックは研究不正等の問題になるのでしょうか。お詳しい方お教えいただけると幸いです。

\newpage





\section{入門：機械学習の一般的問題設定}

この章では、機械学習の問題設定について、関数解析的に定義する。

\begin{defi} データの定義

多数の特徴量とラベルの組、$\mathcal{D}_t:=\{(X_i,Y_i)\}_i\subset \mathcal{X}\times \mathcal{Y}$を時刻$t$のデータと呼ぶ。

また、データ観測前のσ加法族を$\mathcal{F}_0$、データ$\mathcal{D}_t$観測後のσ加法族を$\mathcal{F}_t$と呼ぶ。


\end{defi}
\begin{defi} 推定量
$\mathcal{F}_t$可測な確率変数のことを推定量という。
\end{defi}

データは$\mathcal{D}_1$一つだけのこともあれば、$\mathcal{D}_1,\mathcal{D}_2,......,$と時系列に渡って増え続けることもある。

推定量とは要するに「その時刻の情報で計算可能な数値」である。

\subsection{頻度論的機械学習問題の定義}



\subsubsection{仮説空間}

特徴量空間からラベル空間への写像のうち、手法によってことなる条件を満たすものが為す可分ヒルベルト空間$H$を仮説空間と呼ぶ。この$H$の中から、なるべく良い$f$を選ぶのが、機械学習問題の目的である。



\subsubsection{損失関数}

損失関数$L$と仮説空間$H$の組は次を満たす必要がある。
\begin{defi} 許容可能な組み合わせ

任意の$f\in H$に対して、フレシェ微分に$f$を代入した値$\nabla_fL(f,\omega)$が確率１で$H$に含まれる。
\footnote{実アルゴリズムやその無限次元化等はすべて問題ないので、この条件を意識せずとも別に構わないのですが、非線形変換かつ線形変換を自明に含まない無限次元の仮説空間という非常に病的な機械学習問題を設定する場合に必要になってきます。重箱の隅を突くなんてレベルじゃない話ですが、問題設定は可能な限り一般的に書きたいのでこんな条件が出てくる。}
\end{defi}

$L(f,\omega)$は$\mathcal{F}_1$可測な確率変数である。つまりデータがあってはじめて計算できる。

次の定理は関数解析的定義と、実際のアルゴリズムを結ぶ超重要定理である。

\begin{theo}フレシェ微分はユークリッド空間における勾配の拡張

$H$が有限次元ユークリッド空間$\mathbb{R}^N$と同型であるとき、フレシェ微分はユークリッド空間の勾配$\nabla_\theta,\theta\in\mathbb{R}^N$と一致する。

\end{theo}

この関数解析学における基本的な定理により、本書の定義が実アルゴリズムの一般化であると言うことができる。

\subsubsection{更新則}

初期値関数$f_0\in H$を乱数等によって決定したうえで、この関数は次のように更新されていく。\footnote{$f_0$の決定方法は手法等により様々なテクニックが存在します。}

\begin{align}
f_{n+1}:=f_n-\alpha_n \nabla_f L(f,\omega)
\end{align}

$\{\alpha_n\}$の列を学習率といい、$1e-4$など小さめの数に設定される。後述の焼きなまし法やロビンスモンロー条件等により、数値が下がっていく場合も多い。

この更新を繰り返す行為を「学習」と呼び、$n\to \infty$で$argmin_{f\in H} E[L(f,\omega)]$となる$f$に収束することが示されているのが望ましい。\footnote{本当は解析的に$argmin_{f\in H} E[L(f,\omega)]$を計算できるのが望ましいですが、そのような状況はまずありません。}

\subsection{}

\begin{itembox}[l]{機械学習とはなんなのか}
機械学習とは、AIとは、この特徴量とラベルの関係を記述する関数$f:\mathcal{X}\to \mathcal{Y}$の関数が我々の観測不能な領域に存在すると考え、真の$f$をデータや様々な手法によって手元のコンピューター上に「近似」する手法である。
\end{itembox}

強化学習などの例外を踏まえるといささか乱暴な物言いであるが、初学者や機械学習を数理的に捉えなおしたい方はまずはこの認識を持ってほしい。


\subsection{ベイズ論的問題設定}

本書においてはあまりベイズ論には触れるつもりがないが、せっかくの問題設定なのでベイズ論にも応用しておく。

\begin{defi} 頻度論とベイズ論

$\mathcal{Y}$が$\mathbb{C}^n$or$\mathbb{R}^n$であるとき、この機械学習問題を頻度論的機械学習問題という。

$\mathcal{Y}$が$\mathbb{C}^n$or$\mathbb{R}^n$を台に持つ確率測度の集合であるとき、これをベイズ論的機械楽手問題という。

$\mathcal{Y}$が有限集合上の測度であるとき、頻度論かベイズ論かは事前分布の仮定を置くかによる。

\end{defi}

$\mathcal{X}$から確率測度の台$\mathbb{C}^n$or$\mathbb{R}^n$への写像の集合で、適当なヒルベルト空間に制限したものを$\tilde{H}$とおく

頻度論ではただ一つ真の$f$が存在すると考えたが、必ずしもそうではないと考えるのがベイズ論である。

$\tilde{H}$上に値を取る確率変数$B(\omega)(f)$を考える。当然この分布はデータとは独立ではない。

$B$の$\mathcal{F}_0$条件付き分布を事前分布\footnote{データを見る前に知っている情報等から構成される。}、$\mathcal{F}_1$条件付き分布を事後分布という。\footnote{データを見たあとの分布です}

\begin{theo} ベイズの定理

$B$の$\mathcal{F}_t$条件付き分布を$\mu_t$と置くと

\begin{align}
d\mu_1(g) =\frac{\mathcal{L}(\mathcal{D}_1|g)d\mu(g)}{\int_H \mathcal{L}(\mathcal{D}_1|g')d\mu_0(g')}
\end{align}

\end{theo}

これを用いて、ベイズ推論による$f$は次のように構成される。

\begin{defi} 予測分布

ベイズ推定による$f$を構成する。$\mathcal{Y}$の台上の測度$f(x)$を、$x$に対するラベルの予測分布という。

\begin{align}
df(x)(y):=\int_H 1_{g(x)=y}  d\mu_1(g)
\end{align}

\end{defi}

要するに、ラベル空間の代わりにラベル空間上の測度をラベルと見做すのがベイズ論である。この考え方は、本書終盤の部分観測マルコフ決定過程と共通する。

これは謂わば最尤推定のベイズ化と言えるが、後の様々な頻度論的手法もベイズ化が可能である。具体的にどのような構成になるかは、あまりに記述が煩雑になり読者を置いてけぼりにしすぎるため、興味のある方のみ取り組んでほしい。

相当関数解析力が鍛えられるし、後の強化学習の章ではとんでもなく複雑な関数解析を乱用するため、良い練習にもなるだろう。


\subsection{損失関数の構成例}

ここでは、$L$の具体的な構成について、例を交えつつ解説する。

損失関数は基本的に経験損失項と正則化項に分けられる。


\subsubsection{経験損失}

回帰問題においては、平均二乗誤差という概念を用いる。

二乗誤差とはその名の通り誤差の二乗で$|f(X)-Y|^2$とすることで計算できる。この期待値を求めたい。$X$はi.i.dサンプリングであるため、$X$の出やすさの分布を$dp_X(x)$という測度で表現するとすると、

\begin{align}
E[|f(X)-Y|^2]&=\int_\mathcal{X}|f(x)-y|^2dp_X(x)\\
&=\frac{1}{|\mathcal{D}|}\sum_{X_i,Y_i\in \mathcal{D}} |f(X_i)-Y_i|^2　（モンテカルロ近似）
\end{align}

期待値を計算する際はモンテカルロ法であるため、データの数が多いほど近似制度が良くなる。


次に分類問題について。こちらは基本的に$\mathcal{Y}$が有限集合でありを台に持つ確率測度の隔たり\footnote{回帰問題はただのユークリッド距離でしたが、こちらは距離の公理を満たさないので距離ではありません。そのため「距離」ではなく「へだたり」と書きます。}を測る。

台となる有限集合を$\tilde{\mathcal{Y}}$と置き、データ$Y$はラベル$i$が正解であるとき、$Y=(0,......,1,......0)$(i番目の成分のみ１で残りが０)と表記することにする。有限集合上の確率測度のベクトル表記である。

近似する関数$f$は$x$を受け取り$\tilde{\mathcal{Y}}$上の測度を返す。これを用いて、「正解ラベルに対して何パーセントの確率を返したか」で損失を測る。正解ラベルが５のとき、ラベル５である確率を６０％と判定した場合と、40％と判定した場合では、当然後者のほうが損失が多くなる。

この計算には対数$-\log{p}$を用いる。$p=1$つまり100％そのラベルが正解であると判定しているなら、損失は０となる。

\begin{align}
E[\sum_{j\in\tilde{\mathcal{Y}}} -Y_{\cdot_j} \log{f(X)(j)}]&=\int_\mathcal{X} \sum_{j\in\tilde{\mathcal{Y}}} -Y_{\cdot_j} \log{f(X)(j)}dp_{X}(x)\\
&=-\sum_i\in\mathcal{D} \sum_{j\in\tilde{\mathcal{Y}}} -Y_{i_j} \log{f(X)(j)}
\end{align}

この測度同士の隔たりの計算方法をクロスエントロピー誤差と言う。

\begin{pro}
これらの損失関数のベイズ版を考察せよ。
\end{pro}


\subsubsection{正則化}

突然だが、ここで数列クイズである。

\begin{align}
0,3,8,15,24,35,
\end{align}

と来た時、次の数字はなんだろうか。

賢明な読者なら、$a_n=n^2-1$とすぐに気づき、48と答えるだろう。しかし、本当にそれだけだろうか。

例えば$n^1938576-34567n^35244+......$といったトンデモ式で表現される可能性は考えられないだろうか。

しかし、誰もが$n^2-1$が正しそうだと考える。これは「オッカムの剃刀」と呼ばれる考え方で、「どうせ事象が表現可能なら、単純な構造の方が正しそう」という考え方だ。

これを実現するために、$f$の複雑さそのものを「損失」と考え、経験損失と足し合わせる。これが正則化である。

代表的なものはRidge正則化とLosso正則化である。

\begin{itemize} 
\item Ridge正則化:$||f||^2_H$
\item Losso正則化 $H$がユークリッド空間であるとき、マンハッタン距離$|\theta_1|+|\theta_2|+|\theta_3|+......$と計算する
\end{itemize}

Lossoはパラメータが疎になりやすい（0になるパラメータが多い）というメリットがあり、Ridge正則化は非常に数学的に扱いやすいメリットがある。本書では特に表記なき場合正則化と言えばRidge正則化である。

他にも、原点周りのみ線形で原点から離れたら2乗するいいとこどりの手法も存在する。

正則化項は上記項を0.0001倍など小さな数を掛けて（正則化率という）経験損失に足し合わせる。

$H$がユークリッド空間と同型であるとき、これは「大きなパラメータをなるべく使わない」ということである。特にRidge回帰では、「コンパクト集合外では原点に押し戻す作用がパラメータの大きさに線形に働く」\footnote{2次なので勾配を計算すると線形オーダーになります。}という性質が、GLD等のエルゴード性の考察において非常に重要になって来る。

\subsection{機械学習の具体的な問題設定}
損失関数の構成を踏まえて、有名な機械学習問題等を本書定義に当てはめていく。




\subsubsection{具体例1:線形回帰（フルバッチ）}

上記の定義をもとに、決定論的なフルバッチの線形回帰は次のように書ける。

\begin{align}
\mathcal{X}:&=\mathbb{R}^d\\
\mathcal{Y}:&=\mathbb{R}\\
\mathcal{H}:&=\{f:\mathcal{X}\to\mathcal{Y},f(x)=\sum^J_{j=0}a_j\phi_j(x),a_j\in\mathbb{R},\phi_j:=x^j\}\\
L(f):&=\frac{1}{n}\sum^n_{i=1}|y_i-f(x_i)|^2
\end{align}

ここで、$J,N,\alpha$は使用者自らが決定する変数で、「ハイパーパラメータ」と呼ばれる。

$\mathcal{H}$は$\mathbb{R}^{J+1}$と同型

\subsubsection{具体例2:線形回帰（確率的勾配法）}
\begin{align}
\mathcal{X}&:=\mathbb{R}^d\\
\mathcal{Y}&:=\mathbb{R}\\
\mathcal{H}&:=\{f:\mathcal{X}\to\mathcal{Y},f(x)=\sum^J_{j=0}a_j\phi_j(x),a_j\in\mathbb{R},\phi_j:=x^j\}\\
L(f,\omega)&:=\frac{1}{|I(\omega)|}\sum_{i\in I(\omega)}|y_i-f(x_i)|^2
\end{align}
$I(\omega)\subset \mathcal{D}$はランダムに抽出してきたデータの一部で、確率空間$(\Omega_1,\mathcal{F}_1,P_1)$上で定義されるものとする。

\subsubsection{具体例3:カーネル回帰（フルバッチ）}
$\mathcal{X}:=\mathbb{R}^d,\mathcal{Y}:=\mathbb{R}$と定める。あらかじめ正定値性を満たすカーネル関数$k:\mathcal{X}^2\to\mathcal{Y}$を定めておく。

\begin{align}
\mathcal{H}&:=\mathcal{H}_k\\
L(f)&:=\frac{1}{n}\sum_{i\in I(\omega)}|y_i-f(x_i)|^2
\end{align}


\subsubsection{具体例4:浅いニューラルネット（回帰）}
\begin{align}
\mathcal{X}:&=\mathbb{R}^d\\
\mathcal{Y}:&=\mathbb{R}\\
\mathcal{H}:&=\{f:\mathcal{X}\to\mathcal{Y},f(x)=W_2\eta(W_1x-b_1)-b_2\phi_j(x),W_1\in\mathbb{R}^{L\times d},W_2\in \mathbb{R}^{1\times L},b_1\in\mathbb{R}^L,b_2\in\mathbb{R}\}\\
L(f):&=\frac{1}{n}\sum^n_{i=1}|y_i-f(x_i)|^2
\end{align}

ただし$\eta:\mathbb{R}^L\to\mathbb{R}^L$は活性化関数と呼ばれ、あらかじめ定めておいた非線形でLipsitz連続な関数$\sigma:\mathbb{R}\to\mathbb{R}$を用いて
\begin{align}
\eta_i(z):&=\sigma(z_i)
\end{align}
として定義される。



\subsubsection{具体例5:浅いニューラルネット（分類）}
分類したいクラスの集合である有限集合$C=\{c^{(1)},c^{(2)},......,c^{(m)}\}$に対して、データ$\tilde{\mathcal{D}}=\{x_i,c_i\}^n_{i=1}$が存在している状況で、新たな$x$に対してどのクラスに属するかを予測する。

$\mathcal{X}:=\mathbb{R}^d,\mathcal{Y}:=\mathbb{R}^m$とおき、成形されたデータ$\mathcal{D}:=\{x_i,y_i\}^n_{i=1}$を次のように定義する。

\begin{align}
y_{ij}:=\begin{cases}
    1(c_i=c^{(j)})\\
    0(else)
\end{cases}
\end{align}

このうえで、$\mathcal{H},L$は次のように定義される。


\begin{align*}
\mathcal{H}:&=\{g:\mathcal{X}\to\mathcal{Y},f(x)=softmax(g(x)),g(x)=W_2\eta(W_1x-b_1)-b_2\phi_j(x),\\ 
&W_1\in\mathbb{R}^{L\times d},W_2\in \mathbb{R}^{1\times L},b_1\in\mathbb{R}^L,b_2\in\mathbb{R}\}\\
L(f):&=-\frac{1}{n}\sum^n_{i=1}\sum^m_{j=1}y_{ij}\log{f(x_i)_j}
\end{align*}

この損失関数は交差エントロピーと呼ばれ、$C$上の確率測度間の乖離度合いを表す距離のようなもの（距離の公理は満たさない）

新たな入力データ$x$に対して、$c_{\hat{i}},\hat{i}=argmax_i f(x)$を予測されるクラスとする。


\subsubsection{具体例6:深いニューラルネット（回帰）}
ここでは中間層がN層の場合を扱う。

基本的には具体例4と同じで、$\mathcal{H}$のみが異なる。
\begin{align}
\mathcal{H}:&=\{f:\mathcal{X}\to\mathcal{Y},f(x)=V_{end}g_K\circ g_{K-1}\circ......\circ g_1(x)-b_{end},g_i(x)=\eta(W_ix-b_i)\}
\end{align}





また、自然数列$L:=\{L_1,......,L_K\}$を用いて、$L_0=d$とおくと
\begin{align}
W_i\in \mathbb{R}^{ L_i\times L_{i-1}}\\
b_i\in \mathbb{R}^{L_i}\\
W_{end}\in\mathbb{R}^{1\times L_K}\\
b_{end}\in\mathbb{R}
\end{align}

$K=1$のとき、上記の浅いニューラルネットと等しくなる。

$K>1$のとき、このようなニューラルネットによる学習を「深層学習」という。


\subsubsection{具体例7:ResNet}
近年主流になりつつある、深層学習の亜種である。ここでは本書で使用する定義を書く。


具体例7,8においては、$T\in(0,\infty)$に対して、有限個の数列$t_0=0<t_1<......<t_{K-1}<t_K=T$を用いて

\begin{align}
V_t=V_{t_i} (t\in[t_i,t_{i+1}))
\end{align}

とする。$W,b^1,b^2$についても同様。具体例9,10においてはその限りではない。

この状況下で

\begin{align}
\frac{dX^i_t}{dt}=g(t,X^i_t)\\
X^i_0=x_i
\end{align}

と置き、終端値$X_T$をさらに処理し分類する関数$h$(CNNにおいてはプーリング層と全結合層の合成となる)を用いて損失$L(f),f:=h\bigotimes g$は、フルバッチの回帰問題の場合

\begin{align}
L(f):=\frac{1}{n}\sum^n_{i=1}|y_i-h(X^i_T)|^2
\end{align}

と定義される。

損失関数の値は各データに対する損失の平均と考えることができ$L^{(i)}(f):=\tilde{L}(x_i,f):=|y_i-h(X^i_T)|^2$という関数を用いて

\begin{align}
L(f):=\frac{1}{n}\sum^n_{i=1} L^{(i)}(f)
\end{align}

と書き直せる。ここで4章で重要になる終端値関数を定義する。

\begin{defi} 終端値関数


終端値関数$F:\mathbb{R}^d\to\mathbb{R}$を次のように定義する。

\begin{align}
F(X^i_T):=|y_i-h(X^i_T)|^2
\end{align}


\end{defi}

これは要するに「時系列flowの終端から出力までの関数と、（世間一般で言うところの）損失関数の合成関数」と考えればよい。

実際のところ、明らかに次の等式が成り立つ。

\begin{align}
L(f)=\frac{1}{n}\sum^n_{i=1} F(X^i_T)
\end{align}

ミニバッチ法、分類問題、そして具体例8,9,10の場合も同様に定義する。

損失関数をこう置き換えると、ResNetやSDEnetといった時系列flowモデルに対して、非常に数学的解析がしやすくなる。そのため4章では$L$ではなく$F$を用いて様々な解析を行う。


\subsubsection{具体例8:StochasticDepth}
確率空間$(\Omega_2,\mathcal{F}_2,P_2)$上で定義された、ベルヌーイ分布に従う独立な確率変数列$b_1,b_2,......,b_N$を考える。ただし各$b_i$の確率分布はあらかじめ定められた写像$p$を用いて$p(i)\in(0,1)$に従う。
\begin{align}
x_{i+1}=x_{i}+b_i f(i,x_i)
\end{align}
という形で定義する。

ここで、もしミニバッチなら$(\Omega,\mathcal{F},P):=(\Omega_1,\mathcal{F}_1,P_1)\bigotimes(\Omega_2,\mathcal{F}_2,P_2)$とおく。

\subsubsection{具体例9:ODENet}
\begin{align}
\mathcal{H}&=\{f:\mathcal{H}_1\times\mathcal{H}_2\to\mathbb{Y},f(x)=h_{ab}(x_T)\}\\
\mathcal{H}_1&=\{h:\mathbb{T}\times\mathcal{X}\to\mathcal{X},h(t,x)=V_t\eta(W_tx-b^1_t)-b_t^2\\
\mathcal{H}_2&=\{h_{ab}:\mathcal{X}\to\mathcal{Y},h_{ab}(x)=V_{ab}\eta(W_{ab}x-b^1_{ab})-b^2_{ab}\}
\end{align}

ただし、$x_0:=x,x_t:=\int^t_0 h(s,x_s)ds$とおく。

\subsubsection{具体例10:SDENet}
上記のODEnetを確率化する。
\begin{align}
\mathcal{H}&=\{f:\mathcal{H}_1\times\mathcal{H}_2\to\mathbb{Y},f(x)=h_{ab}(X_T)\}\\
\mathcal{H}_1&=\{h:\mathbb{T}\times\mathcal{X}\to\mathcal{X},h_1(t,x)=V_t\eta(W_tx-b^1_t)-b_t^2,h_2=V^2_t\eta(W^2_tx-b^{12}_t)-b_t^{22}\}\\
\mathcal{H}_2&=\{h_{ab}:\mathcal{X}\to\mathcal{Y},h_{ab}(x)=V_{ab}\eta(W_{ab}x-b^1_{ab})-b^2_{ab}\}
\end{align}
ただし、$X_0=x$であり、$X$は$dX_t=h_1(t,X_t)dt+h_2(t,X_t)dB_t$という確率微分方程式に従うものとする。

確率空間は$(\Omega,\mathcal{F},P):=(\Omega_1,\mathcal{F}_1,P_1)\bigotimes(B,\mathcal{B}(B),\mu)$と置く。ただし$(B,\mathcal{B}(B),\mu)$は$B:=C([0,T])$とした場合のWiener空間である。$h_1,h_2$が$x$に対して大域的Lipschitz連続で$t$に対して$1/2$次Hölder連続と置くことで、$X_T\in\mathbb{D}^\infty$となる。つまり$X_T$がWiener汎関数と言え、上記の定義での損失関数が定義でき、またMalliavin微分や部分積分の議論に持ち込める。



\subsection{活性化関数の具体例}
上述の$\sigma(x)$について、一応大域的Lipsitz連続で非線形であればなんでもいいことになっているが、当然よく使われるものは存在する。

\subsubsection{ReLu}
\begin{align}
\sigma(x):=max(0,x)
\end{align}
と定義される。「if文一つで書ける」「勾配が消失しない」といった利点がある。

区分的に滑らかな関数を近似するにあたってこの形が都合がいいとする研究もある

本書では連続的に微分可能ではないこと、零点がLebesgue測度無限大に存在すること、区分的に微分しても2階微分が零関数になることなどから6章1項を除いて採用しない。

\subsubsection{swish}
\begin{align}
\sigma(x):=x\cdot sigmoid(x)\\
sigmoid(x):=\frac{1}{1+e^{-x}}
\end{align}
近年Reluにとって代わって使われ始めている活性化関数。原点から離れるほどReluに近づく。

$C^\infty$であること、任意の階数の導関数も含めて零点がLebesgue測度0であることなどから、準楕円性などを考察する状況おいては非常に都合がよく、原則こちらを用いることにする。

\newpage
\section{入門：ニューラルネットの積分表現理論}

\subsection{ニューラルネットの連続化}

特徴量空間$\mathcal{X}(:=\mathbb{R}^d)$から、$\mathbb{C}$への写像を構成する浅いニューラルネット考える。

\begin{align}
f(x)=W_2\eta(W_1x-b_1)
\end{align}


ただし、$W_2$は$1\times J$複素行列、$W_1$は$J\times d$実行列、$b_1$は$J$次元実ベクトルであるとする。

また$\eta:\mathbb{R}^J\to\mathbb{C}^J$であり、ある非線形で大域的リプシッツ連続な写像$\sigma:\mathbb{R}\to\mathbb{C}$を用いて,$\eta_i(y)=\sigma(y_i)$と書けるとする。


この計算をベクトル$a\in\mathbb{R}^d,b\in\mathbb{R},\sigma,c\in\mathbb{C}$を用いて書き直す
\begin{align}
f(x)=\sum^J_{i=1}c_i\sigma(a_i\cdot x-b_i)
\end{align}

ここで、$J\to\infty$とした形

\begin{align}
f(x)=\int_{\mathbb{R}^{d+1}}\gamma(a,b)\sigma(a_i\cdot x-b_i)dadb
\end{align}

これを積分的ニューラルネットと呼ぶ。積分的ニューラルネットに対しては、正則化付き損失関数に対する大域的最適解が解析的に求められる場合がある。そのため、十分広いニューラルネットに対して、最適なパラメータの近似値が一回の数値計算で求められることになる。



この章では、特徴量空間上の測度$\mu$（データの分布）と、それに対して後の許容条件を満たすように自由に設定できる測度パラメータ空間上の測度$\lambda$を扱えるようにするため、[2]で提唱された再生核Hilbert空間上のRidgelet解析を[3]による再生核Hilbert空間の理論により我流の再構成を行う。

\subsection{再生核Hilbert空間上の積分表現理論}

$\mathcal{X}$上の複素数値関数全体の集合を$\mathcal{F}(\mathcal{X})$とおく。

パラメータ$a,b$の成す空間$\mathbb{R}^{d+1}$から$\mathbb{C}$への写像のうち、$\mathbb{R}^{d+1}$上の測度$\lambda(dadb)$による$L^2$空間を$\mathcal{G}(:=L^2(\mathbb{R}^{d+1}\to\mathbb{C},\lambda(dadb)))$とおく。

写像$h:\mathcal{X}\to\mathcal{G}$を固定し、次のような積分作用素$S:\mathcal{G}\to\mathcal{F}(\mathcal{X})$を、$F\in\mathcal{G}$に対して、$f=SF$となる$f\in\mathcal{F}(\mathcal{X})$を、次の等式が成り立つ関数とすることによって定義する。
\begin{align}
f(x)=\langle F,h(x)\rangle_\mathcal{G}
\end{align}

ここで、$S$の像空間$\mathcal{E}(S):=S(\mathcal{G})$に対して、次のようにノルムを入れる。
\begin{align}
||f||_{\mathcal{E}(S)}:=inf\{||F||_\mathcal{G}:SF=f\}
\end{align}


\begin{theo} 再生核Hilbert空間([3])

$k:\mathcal{X}^2\to\mathbb{C}$を次のように定義する。

\begin{align}
k(x,y):=\langle h(y),h(x)\rangle_\mathcal{G}
\end{align}

この時、$\mathcal{E}(S)$は再生核$k$を持つ再生核Hilbert空間

$\{h(x),x\in\mathcal{X}\}$が$\mathcal{G}$上完全であることと、$S$が等距離写像であることは同値

\end{theo}

今後、この$\mathcal{E}(S)$を、再生核Hilbert空間であることを強調するために$H_k$と表記する。

\begin{theo} 等距離元の存在([3])

任意の$f\in H_k$に対し
\begin{align}
||f||_{H_k}=||F^*||_\mathcal{G}
\end{align}
を満たす$F^*\in\mathcal{G}$が一意に存在する
\end{theo}

この$F^*$を$f$のRidgelet変換と呼び、$\mathcal{R}f$と表記する。

今後、定数$K$を$\mathcal{X}$上の測度$\mu$を用いて,$K:=\int_\mathcal{X}k(x,x)\mu(dx)$と表記する。

$0<K<\infty$の時、この$(\mu,\lambda,h)$の組は「許容条件を満たす」と呼ぶ。

\begin{theo} 積分作用素の連続性

$(\mu,\lambda,h)$が許容条件を満たすとき、$H_k\subset L^2(\mathcal{X},\mu)$であり、$S:\mathcal{G}\to L^2(\mathcal{X},\mu)$は連続作用素

proof.

$H_k$上の関数列$\{u_j\}^\infty_{j=1}$を、$\mathcal{G}$の正規直交基底$\{v_j\}^\infty_{j=1}$を用いて

\begin{align}
u_j(x):=\langle v_j ,h(x)\rangle_\mathcal{G}
\end{align}

と定義する。両辺の$L^2(\mathcal{X},\mu)$上のノルムを取る。

\begin{align}
||u_j||^2_{L^2(\mathcal{X},\mu)}&=\int_\mathcal{X} u_j(x)\overline{u_j}(x) d\mu(x)\\
&=\int_\mathcal{X}(\int_{\mathbb{R}^{d+1}} v_j(z)\overline{h(x)(z)}d\lambda(z)\overline{\int_{\mathbb{R}^{d+1}} v_j(z)\overline{h(x)(z)}d\lambda(z)} )d\mu(x)\\
&\leq \int_\mathcal{X}(\int_{\mathbb{R}^{d+1}} v_j(z)\overline{v_j(z)}d\lambda(z)\int_{\mathbb{R}^{d+1}} h(x)(z)\overline{h(x)(z)}d\lambda(z) )d\mu(x) (Schwarzの不等式)\\
&= K||v_j||^2_\mathcal{G}
\end{align}

$u_j=Sv_j$であることを踏まえると、任意の$F\in\mathcal{G}$は$\{v_j\}^\infty_{j=1}$の線形和で書けるため、同じ議論により

\begin{align}
||SF||_{L^2(\mathcal{X},\mu)}\leq K||F||_\mathcal{G}
\end{align}

となる。$f\in H_k$にはすべて$f=SF$となる$F$が存在するため、定理の主張が言える。
\end{theo}

許容条件に加え、$\{h(x):x\in\mathcal{X}\}$が$\mathcal{G}$上完全であるとき、「強い意味で許容条件を満たす」と呼ぶとする。

\begin{theo} $H_k$の正規直交基底

強い許容条件が満たされるとき、$\{u_j\}^\infty_{j=1}$は$H_k$の正規直交基底

proof.

上記の定理より、$||f||_{H_k}=||F^*||_\mathcal{G}$となる$F^*$が存在し、また内積の線形性から、複素数列$\{c_j\}^\infty_{j=1},\sum |c_j|^2<\infty$を用いて

\begin{align}
F^*=\sum_j c_j v_j\\
f=\sum_j c_j u_j
\end{align}

と書ける。強い許容条件が満たされる場合、$S$は等距離写像。そのため$f=u_j$としたとき$F^*=v_j$である。

一般の$f,F^*$に対して、Parsevalの等式より$||F^*||_\mathcal{G}=\sum |c_j|^2$で、これは$||f||_{H_k}$と一致する。

分極公式により$H_k$の内積は$||\cdot ||_{H_k}$から陽に書け、$\langle u_j ,u_i\rangle=\delta_{ij}$が言える。

\end{theo}

次はさらに強い条件を課す。この定理の条件を緩めていくことこそが、我々の再定義した積分表現理論における今後の課題となる。

\begin{theo} Ridgelet変換の積分表示定理([3])

$(\mu,\lambda,h)$は強い意味で許容条件を満たし、さらに任意の$f\in H_k$に対して$||f||_{H_k}=||f||_{L^2(\mathcal{X},\mu)}$が成り立つとする。

また、単調増大な$\mathcal{X}$の部分集合列$\{E_N\}^\infty_{N=1}$を、$\cup^\infty_{N=1} E_N=\mathcal{X}$となるようにとり

\begin{align}
(\mathcal{R}_Nf)(z):=\int_{E_N} f(x) \overline{h(x)(z)}\mu(dx)
\end{align}

と置く、任意の$N$に対して$F_N\in\mathcal{G}$なら

\begin{align}
||\mathcal{R}_Nf-\mathcal{R}f||_\mathcal{G}\to 0(N\to\infty) 
\end{align}
\end{theo}

この定理によって$F^*$はまさに既存のRidgelet変換そのもので、既存研究は$\mu(dx)=dx$と置いた場合であることがわかる。

今回の再定義の利点は、$\mu$をデータの分布とすることで、よりデータに沿った形でRidgelet変換を定義できることにある。

実問題では、有限個のデータ$(x_i,y_i)^n_{i=1}$から、なるべく"良い"写像$y=f(x)$を構成したい。既存のRidgelet解析では、このRidgelet変換を近似するにあたって

\begin{align}
(\mathcal{R} f)(a,b):&=\int_{\mathbb{R}^d} f(x)\sigma(a\cdot x-b)dx\\
&\approx \frac{1}{n}\sum^n_{i=1} f(x_i)\sigma(a\cdot x_i-b)\\
&\approx \frac{1}{n}\sum^n_{i=1} y_i\sigma(a\cdot x_i-b)
\end{align}

とするしかない。しかしこの近似は積分の測度がLebesgue測度である場合は不自然な近似となっている。実際のデータは一様分布には程遠く、一様に近い分布になるようデータの一部を抽出するのは、$d$が大きい状況では非常に難しい。

ここで$dx$を特徴量データの分布$\mu(x)$に差し替えれば、上記の近似計算はモンテカルロ法として非常に自然なものとなる。



\subsection{(先端研究)定義域の制限}

Reluは実装が楽で計算も早いが、簡単に爆発するため扱いにくい。\footnote{厳密には爆発を抑えてくれない。}

[4]では



\newpage

\section{残差学習の微分方程式解釈}



\subsection{ResNetと微分方程式}
深層学習においては、単純に層を深くしすぎると性能が下落することが知られていた。

そこで2015年Microsoftの研究者から発表されたResNet[4]が、この問題を大きく改善し、現在の深層学習における主流となった。

既存の深層学習では、あるブロックに学習させたい関数$h(x)$をそのまま学習させていたが、ResNetの中核となる残差学習と呼ばれる手法では残差関数$f(x):=h(x)-x$を学習する。

その後$x+f(x)$を次のブロックの入力とすることで、実質的に$h(x)$を学習させたことと同じになる。([4]ではさらにこの後ReLuを通したものを次のステップの入力としていたが、後に[5]などの論文でこれを直接次のステップの入力としたほうが良いことが検証されている。そのため本書では通してこちらの流儀を用いる)

$n$ブロック目の入力を$x_n$と置き、残差関数$f_n$とおけば

\begin{align}
x_{n+1}=x_n+f_n(x_n)
\end{align}

これは常微分方程式のEuler近似に他ならない。




[6]ではこの考えのもとで、

\begin{itemize}
\item ResNet:Euler法
\item PolyNet:後退Euler法
\item FractalNet:2次Runge–Kutta法
\item RevNet:連立ODEのEuler法
\end{itemize}

という分類をしたうえで、線形多段法を用いて新たな残差学習ネットを構成し、性能の向上に成功した。

NIPS2018の優秀論文に選ばれた[5]は、さらにこの考えを発展させ

\begin{align}
\dot{x_t}=f(t,x_t)
\end{align}

という常微分方程式の$f(t,x_t)$を直接学習させるという手法を提案した。

また[6]では、ShakeShakeモデルやStochasticDepthといった確率的残差学習モデルは、確率微分方程式の簡易スキームであることを主張している。

たとえば、Stochastic Depthは

\begin{align}
X_{n+1}=X_n+b_nf_n(X_n)
\end{align}

という計算が行われる。ここで$b_n$は、あらかじめ定められたパラメータ$p_n\in(0,1)$に従う Bernoulli分布である。

この確率過程は

\begin{align}
dX_t=p(t)f(t,X_t)dt+\sqrt{p(t)(1-p(t))}f(t,X_t)dB_t
\end{align}

というSDEの簡易スキームであるといえる。ただしBrown運動は一次元であるとする。

より一般の確率微分方程式
\begin{align}
dX_t=f(t,X_t)dt+g(t,X_t)dB_t
\end{align}
我々はこの確率的残差学習の連続化をSDEnetと名付け、理論的解析およびSDEの数値解析手法を用いた新型残差学習ネットワークの構築を行った。


\subsection{損失関数の微分可能性}
この項のみ、活性化関数をReLu $\sigma(x):=max(0,x)$と置く。

この項では、まず活性化関数に関係なくFeynman–Kacの公式を用いてSDEnetの偏微分方程式での定式化を考える。最後にはtoy modelとして一次元のSDEnetを考え、確率化によってパラメータの微分可能性が向上していることを証明する。

次のような$[0,T]$上で定義された連立SDEを考える。

\begin{align}
X^{s,x,\theta}_t=x+\int^t_sf(r,X^{s,x,\theta}_r,\theta)dr+\int^t_sg(t,X^{s,x,\theta}_r,\theta)dB_r\\
Y^{s,x}_t=F(X_T)+\int^T_t Z_s dB_s
\end{align}

活性化関数はReLuなので、Lipschitz条件と増大条件は問題なく成り立ち、解の存在と一意性が言える。

ここで、$Z_s$は$X,Y$から定まる、マリアヴァン微分で計算できる確率過程だが、この正体自体はあまり問題ではない。重要なのは次の偏微分方程式である。

[12]の定理を用いて
\begin{align}
\frac{\partial u}{\partial t}(t,x,\theta)+\mathcal{L}u(t,x,\theta)=0
F(x)=u(T,x,\theta)
\end{align}


と置くと、$u(t,x)=E[F(X^{t,x,\theta}_T)]$、すなわち「時刻$t$で$X_t=x$だったという条件付きの$F(X_T)$の期待値」である。

ただし、楕円型作用素$\mathcal{L}$は次のように定義される。この作用素は、次の勾配法連続化議論においても重要である。

\begin{align}
\mathcal{L}u(t,x,\theta):=\nabla_x u(t,x,\theta) f(t,x,\theta)+\sum^d_{i,j} [g^*g]_{i,j}(t,x,\theta)\frac{\partial^2 g}{\partial x_i\partial x_j}(t,x,\theta)
\end{align}


$u(0,x,\theta)$の$\theta$での微分を考えることはまさしく全体の損失のパラメータ勾配を考えることに他ならない

ここで、簡易モデルとして$g＝I_d$(単位行列)とすると、このPDEの解は[8][9]より次の定理が成り立つ。

\begin{theo}

$f(t,x):=w_2\eta(w_1 x-b_1)+b_2$と置く。ただし$\eta$はReluであるとする。

SDEの解とBrown運動が次の等式を満たす。

\begin{align}
P(\int^T_0f^2(X_t)dt<\infty)=1 \\
P(\int^T_0f^2(B_t)dt<\infty)=1 
\end{align}

このとき、次の等式が言える。

\begin{align}
u(t,x,\theta)=E^x[F(W_{T-t})exp[\int_0^{T-t} f(t+r,B_r,\theta)dB_r-\frac{1}{2} \int^{T-t}_0||f(t+r,B_r,\theta)||^2dr]]
\end{align}


proof.

[8]より前半部分が言えればGirsanov変換ができ、Girsanovの定理を使えれば[9]により解を陽に書ける。



$x$以外は定数なので、上記の定理を使う際は$f(x)=\eta(x)$と置いて一般性を失わない。

まずは簡単な$P(\int^T_0f(W_t)dt<\infty)=1 $を示す。

$M(\omega):=max_{0\leq t \leq T}W_t(\omega)$と置くと、$M(\omega)$は確率１で有限。

よって
\begin{align}
\int^T_0f^2(W_t)dt\leq T M^2(\omega)<\infty
\end{align}

か確率１で成り立つ。

$P(\int^T_0f^2(X_t)dt<\infty)=1$について証明する。

$f^2(X_t)\leq X^2_t$なので、$X_t$の連続性から上と同じ議論により明らか


\end{theo}


ここからはtoy modelとして一次元の場合、$f(t,X_t,\theta)=a\sigma(bx-c)-d,\theta=[a,b,c,d],ab\neq0$を考える。$\sigma$はReluなので$\sigma(x)=max(0,x)$すると次の定理が成り立つ

\begin{theo} 損失関数の微分可能性

PDEの解$u(0,x,\theta)$はパラメータ$a,b,c,d$に対して$C^\infty$



proof.

$a,d$は明らか。$b,c$についてのみ証明する。

熱核の理論より、SDEの解$X$の推移確率密度$p(t_1,x,t_2,y)$を用いて

\begin{align}
u(t,x)=\int_\mathbb{R}F(y)p(t,x,T,y)dy
\end{align}

と書ける。

よって、$\int_0^{T-t} f(B_r,\theta)dB_r$の密度関数に対する$\theta$の滑らかさが言えればよい。

$\partial_x A(x,\theta)=f(x,\theta)$となるような関数$A$を考え、$A(B_t,\theta)$に対して伊藤の公式を用いると

\begin{align}
\int^{T-t}_0b(r,B_r,\theta)\odot dB_t=B(T-t,B_{T-t},\theta)-\frac{1}{2}ab\int^{T-t}_0 1_{bB_s-c>0}ds
\end{align}
が言える。

厳密には伊藤の公式は使えないが、ReLuに近似する滑らかな関数列の極限を考えることで実現する。


ここから、$b,c$の微分可能性を言いたいので、$[0,T-t]$間での、$B_{T-t}=y$となるBrown橋に対して、$B_s>c/b$の滞在時間の密度が$b,c$に対して滑らかであればよい。$b$は0でないので、定義域上$c/b$は$C^\infty$なので、$B_s>l$と置き、滞在時間の密度が$l$に対して滑らかであればよい。

[9]より、0出発で時刻$r$で$y$にたどり着くBrown橋の$l$以上の滞在時間が$s$以下である確率$P^s_l(\tau|y)$は




\begin{align}
P^r_l(\tau|y)=\begin{cases}
    1-(r-\tau)e^{-\frac{c}{\tau}+\frac{y^2}{2}} (e^c(2c+1)erfc(\sqrt{c})-2\sqrt{\frac{c}{\pi}})　y\leqq l\\
    \int^\tau_0\frac{(\tau-u)e^{\frac{y^2}{2}-\frac{l^2}{2(r-u)}-\frac{(y-l)^2}{2u}}}{\sqrt{2\pi}(u(r-u))^{\frac{3}{2}}}\times (\frac{l(y-l)^2}{u}-\frac{(y-l)^2l^2}{r-u}+y-2u)du　0\leqq l \leqq y\\
    1-P^r_{-y}(r-\tau)　l\leqq 0
\end{cases}
\end{align}

であるため、これは$l$に対して$C^\infty$である。あとはこれを$\tau$で微分しても$l$に対する微分可能性は変わらないので、定理が示された。


\end{theo}

　

活性化関数が$Relu$の時、拡散項がない（確率的でないResNet）に対応する移流方程式
\begin{align}
\partial_t u(t,x,\theta)-\nabla_x u(t,x,\theta)f(t,x,\theta)=0\\
u(T,x)=F(x)
\end{align}
の解$u$は、明らかに$b,c$に対して微分不可能である。

上記の定理は、ResNetの確率化による平滑化で、パラメータの微分可能性が向上することを示している。



\subsection{Malliavin解析を用いた勾配誤差の漸近評価}
$0=t_0<t_1<......<t_N<T$という時間列と、次のようなオイラー丸山近似を考える。

\begin{align}
X_{t_{n+1}}=X_{t_n}+f(t,X_{t_n})(t_{n+1}-t_n)+g()
\end{align}

\begin{theo} 近似誤差収束定理[13]

$f,g$がLipschitz条件と増大条件を満たすとする。このとき

任意の$p>1$に対して 

\begin{align}
sup_NE[|X_T^N|^p]<\infty\\
E[sup_{t\in[0,T]}|X_t-X^N_t|^p]\to 0 (N\to\infty)
\end{align}

\end{theo}





確率的残差学習を確率微分方程式の離散化とし、このサンプリングで計算された勾配を真のSDEモデルにおける勾配の推定値とするには、ある$C(T,x,F)$が存在し
\begin{align}
|\frac{\partial }{\partial \theta}E[F(X_T)]-\frac{\partial }{\partial \theta}E[F(X_N)]|\leq C(T,x,f)\frac{T}{N}
\end{align}
が$f$を構成するパラメータ$\theta$に対して成り立つ必要がある。これを仮定すれば、$N\to\infty$で両辺が0に収束する。



\begin{theo} 勾配誤差の漸近評価
$0=t_0<t_1<......<t_N<T$とおく。

確率微分方程式$X^\theta_T$とその離散近似確率過程$X^{\theta,N}_T$を考える。
\begin{align}
dX^\theta_t=X_0+\int^t_0f(s,X^\theta_s,\theta)ds+\int^t_0g(s,X^\theta_s,\theta)dB_s\\
dX^{\theta,N}_t:= X_0+\int^t_0 f(\psi(s),X^{\theta,N}_{\psi(s)})ds+\int^t_0 g(\psi(s),X^{\theta,N}_{\psi(s)})ds
\end{align}

ただし$\phi(t):=max[t_n:t>t_n]$とする。


$f,g$は$x$に対して$C^\infty$かつ大域的Lipschitz連続で1次の増大度を持つ。$f,g$は$\alpha$に対して微分可能で、$t$に対して$1/2$次ヘルダー連続であるとする。

また、$F$は多項式増大な可微分関数であるとする。すなわち、ある$n$と定数$\tilde{M}$が存在し$F(x)\leq M(|x|^n+1)$であるとする。


$d\times d$行列列$\{L_n\}^{d-1}_{n=1}$を次のように定義する。

\begin{align}
L_1&:=-(\frac{\partial f}{\partial x})^2+\frac{\partial \frac{\partial f}{\partial x}f}{\partial x}\\
L_{n+1}:&=\frac{\partial f}{\partial x}L_n-\frac{\partial L_n f}{\partial x}\\
\end{align}

$[f(0,x),L_1f(0,x),......,L_{d-1}f(0,x)]$が、$x\in \mathbb{R}^{d+1}$上ほとんどいたるところで一次独立性を持つとする。

この仮定の下で定数$C(T,x,F)$は存在し、ある定数$p>1,q>0,K(T,x)>0,M(f,g,F)>0$が存在し


\begin{align}
|\frac{\partial }{\partial \theta}E[F(X_T)]-\frac{\partial }{\partial \theta}E[F(X_N)]|\leq K(T,x)M(f,g,F)||1/\det(\gamma_T)||^q_p\frac{T}{N}
\end{align}


ただし、$\gamma_T:=\gamma_{X_T}$であり、確率変数$X_T$のMalliavin共分散行列である。

proof.

他のパラメータは固定し、無作為に中質した一つのパラメータ$\alpha$に対して言えれば十分である。


[6]では、$\mathcal{A}$は$\alpha$のとる定義域（一般には$\mathbb{R}$）としたうえで、ある実数$\eta>0$が存在し、$v:=\partial_\alpha f $or $g$として

\begin{align}
sup_{t,x,\alpha,\alpha^`\in [0,T]\times \mathbb{R}^d\times \mathcal{A}\times\mathcal{A}} \frac{|v(t,x,\alpha)-v(t,x,\alpha^`)|}{|\alpha-\alpha|^\eta}
\end{align}

が成り立つという条件の下でこの定理が成り立つことが証明されている。



今回、考えたいResNetの$f,g$は、活性化関数をswishで考えているため、この式を満たさない。

さらに、$|\frac{\partial F}{\partial x}(x)|$が$x$に対して有界であることを課しており、$F$が$x$に対して2次のオーダーになる機械学習の実問題にはそぐわない。

そのため、この定理を拡張するために順を追って補題を積み重ねていく。


\end{theo}


\begin{ho} 勾配過程の表記[11] 

$f,g,\partial_\alpha f,\partial_\alpha g$が共に任意の$t,\alpha$に対して、$x$に大域的Lipsitz連続であるとし、$f,g$は１次の増大条件を満たすとする。

また、確率過程$Y_t:=\nabla_x X_t,Z_t=Y_t^{-1},\dot{X}_t=\partial_\alpha X_t$と道ごとの微分やその逆行列の存在を仮定し定義すると

\begin{align}
Y_t=I_d+\int^t_0 \partial_x f_s Y_s ds+\int^t_0 \sum^n_{j=1} (\partial_x g_s)_{j} Y^j_s dB^j_s\\
Z_t=I_d-\int^t_0 Z_s(\partial_x f_s-\sum^q_{j=1}(\partial_x g_s)^2_j )ds-\sum^n_{j=1}\int^t_0 Z_s (\partial_x g_s)_jdB^j_t \\
\dot{X}_t= \int^t_0 \partial_\alpha f_s+ \partial_x f_s \dot{X}_sds+\sum^n_{j=1}\int^t_0 \partial_\alpha g+ \partial_x g\dot{X}_sdB^j_s
\end{align}
と書ける。ただし関数$h$に対し、$h_s:=h(s,X_s,\alpha)$とする。


このとき

\begin{align}
\dot{X}_t=Y_t\int^t_0 Z_s[(\partial_\alpha f-\sum^n_{j=1}\partial_x g_{j,s}\partial_\alpha g_{j,s})ds+\sum^n_{j=1} \partial_\alpha g_{j,s}dB_s]
\end{align}

\end{ho}

次の補題はMalliavin解析の議論につなげていくにあたって非常に重要となる。

\begin{ho} Wiener汎関数[10]

上述のLipschitz条件と増大条件に加え、$f,g$は$x$に対して$C^\infty$級であるとする。また、任意の$i,j$に対して$f_i(t,0),g_{ij}(t,0)$は$t$に対して有界であるとする。このとき$X^i\in\mathbb{D}^\infty$
\end{ho}

$\mathbb{D}^\infty$はWiener汎関数空間と呼ばれ、Malliavin微分の意味でのSobolev空間$\mathbb{D}^{k,p}$を用いて
\begin{align}
\mathbb{D}^\infty:=\cap_{k,p\geq 1}\mathbb{D}^{k,p}
\end{align}
と定義される。

\begin{ho} Malliavin微分[10]
\begin{align}
\mathcal{D}_sX_t=Y_tZ_sg(s,X_s)1_{s\leq t}
\end{align}
\end{ho}

\begin{ho} Clarkの表現定理[10]
$X_T\in\mathbb{D}^\infty$のとき(実際には$X_T^i\in\mathbb{D}^{1,1}$の場合まで拡張が可能)

\begin{align}
X_T=E[X_T]+\int^T_0 E[\mathcal{D}_tX_T|\mathcal{F}_t]dB_t 
\end{align}


\end{ho}



\begin{defi} Malliavin共分散行列[10]

$A=(A_1,A_2,......,A_d)^T,A\in\mathbb{D}^\infty$とする。

このとき、Malliavin共分散行列$\gamma_F$を次のように定義する。

\begin{align}
\gamma_A:=\int^T_0 D_tA[D_tA]^* dt
\end{align}

この行列が確率１で正則で

\begin{align}
\gamma_A\in \cap_{p\geq 1}L^p(\Omega)
\end{align}

であるとき、$F$のMalliavin共分散行列は非退化であるという
\end{defi}

$f,g$が次のHörmander条件を満たす点$x_0$に対し、$X_0=x_0$となるSDEの解のmalliavin共分散行列は非退化であり、またその確率密度関数$C^\infty$となることが知られている([15])。


\begin{defi} Hörmander条件(Brown運動一次元)

次のようなベクトル場を考える。

\begin{align}
D=\sum^d_{i=1}f_i(0,x_0)\frac{\partial}{\partial x_i}-\frac{1}{2}\sum^d_{i=1} \sum^d_{j=1}g_j(0,x_0) \frac{\partial g_i}{\partial x_j} (0,x_0)\frac{\partial}{\partial x_i}\\
C=\sum^d_{i=1}g_i(0,x_0)\frac{\partial}{\partial x_i}
\end{align}

ベクトルの無限組$C,[C,D],[[C,D],C],[[C,D],D],[[[C,D],D],C],......$が、$\mathbb{R}^d$を張るとき、SDEの解$X$は初期点$x_0$に対してHörmander条件を満たすと言う

ただし$[X,Y]$はLie括弧積であるとする。

\end{defi}

イメージとしては、要するに退化したSDEに対しても、Brown運動が全方向に"効いている"というものである。

\begin{theo} 密度関数の滑らかさの一様評価

確率変数$X_0$は確率密度関数を持ち、またSDEはほとんどいたるところHörmander条件を満たすとする。

このとき$X_t(t>0)$の密度関数は$C^\infty$級


proof.

$X_T$の場合のみを示せば十分である。

$X_0=x_0$のSDEに対して$X_T$の確率密度関数を$p_T(x|x_0)$と表記する。上記の定理により、$x_0$がHörmander条件を満たす点なら、これは$C^\infty$級

\begin{align}
p_T(x)=\int_{\mathbb{R}^d} p_T(x|x_0)p_0(x_0)dx_0
\end{align}

これの$x$に対する微分可能性を見ればよい。




\end{theo}


さて、今回考えたいSDEを再度表記しよう

\begin{align}
dX_t=p(t)f(t,X_t)dt+\sqrt{p(t)(1-p(t))}f(t,X_t)dB_t
\end{align}

$f$が$g$の定数倍であること、Brown運動が1次元であることが今回のポイントである。

$p_t=0,1$の時、元の離散版であるstochastic depthに当てはめると「かならずその層をスキップするorかならずその層の関数を用いる」となり、確率要素が消える。実際、Hörmander条件も自明に満たされない。


通常、Brown運動の次元がSDEと等しく($n=d$)、被確率積分行列が単位行列のようなものだった場合、Hörmander条件は自明に満たされる。今回のようなBrown運動の次元が小さい場合は、Hörmander条件はLie括弧積の計算をして確認せざるをを得ない。




\begin{theo} Hörmander条件

$d\times d$行列列$\{L_n\}^{d-1}_{n=1}$を次のように定義する。

\begin{align}
L_1&:=-(\frac{\partial f}{\partial x})^2+\frac{\partial \frac{\partial f}{\partial x}f}{\partial x}\\
L_{n+1}:&=\frac{\partial f}{\partial x}L_n-\frac{\partial L_n f}{\partial x}\\
\end{align}

$[f(0,x),L_1f(0,x),......,f_{d-1}(0,x)]$が、$x\in \mathbb{R}^{d+1}$上ほとんどいたるところで一次独立性を持つとする。

このとき、$\mathbb{R}^d$上ほとんどいたるところHörmander条件を満たす。



proof.

$X^T$の場合のみを示せば十分である。

あまりに乱雑なので機械学習特有のベクトルのベクトル微分表記を用いて、ベクトル場とLie括弧積を次のように略記する。

\begin{align}
C&=g\\
D&=f-\frac{1}{2}\frac{\partial g}{\partial x}g\\
[X,Y]&=\frac{\partial B}{\partial x}A-\frac{\partial A}{\partial x}B
\end{align}

ただし、$C=g$とは$C=\sum^d_{i=1}g_i(0,x_0)\frac{\partial}{\partial x_i}$の略記である。ほかのベクトルについても同様。

まず最初のLie括弧積を考える

\begin{align}
[D,C]=\frac{\partial g}{\partial x}(f-\frac{1}{2}\frac{\partial g}{\partial x}g ) -(\frac{\partial f}{\partial x}-\frac{1}{2}\frac{\partial \frac{\partial g}{\partial x}g}{\partial x})g
\end{align}

\begin{align}
D^0:&=D\\
D^{n+1}:&=[D^n,C]\\
L_1&:=-(\frac{\partial g}{\partial x})^2+\frac{\partial \frac{\partial g}{\partial x}g}{\partial x}\\
L_{n+1}:&=\frac{\partial g}{\partial x}L_n-\frac{\partial L_n g}{\partial x}\\
\end{align}

として定義すると任意の自然数$n$に対して
\begin{align}
D^{n}:&=L_ng
\end{align}

つまり$(g,L_1g,......,L_{d-1}g)$が一次独立であればよい。

\end{theo}
この定理はSDEがHörmander条件を満たすための十分条件を述べているに過ぎない。(DにひたすらCのみを掛け合わせているため。回数も$d$回以上であってもよい。)しかし$f=Mg$($M$は定数)という条件下では、必要十分条件に近いと思われる。



\begin{theo} 部分積分の公式[10]

$\beta$を多重指数とする。また$A\in\mathbb{D}^{k_1,\infty}$のMalliavin共分散行列は非退化、$B\in\mathbb{D}^{k_2,\infty}$とする。

十分滑らかな実数値関数$F$,確率変数$A\in\mathbb{D}^\infty$に対し、$\beta,A,B$から定まるある確率変数$H_\beta(A,B)\in L^p(\Omega)$が存在し

\begin{align}
E[\partial_\beta F(A)B ]=E[F(A)H_\beta(A,B)]
\end{align}

\end{theo}






\begin{theo} エラー確率変数の評価[16]


測度$\tilde{\mu}$を次のように定義する。

\begin{align}
\int_{\mathbb{R}^d}h(x)\tilde{\mu}(x)=E[h(X^{0,N}_T)+h(X^{1,N}_T)]+\int^1_0E[h(X^{\lambda,N}_T)]d\lambda
\end{align}

ただし$\lambda\in[0,1]$で$X_t^{\lambda,N}:=\lambda X_t+(1-\lambda)X^N_t$とする。


また、$\epsilon\in(-1,1)$を置く(この区間は0を含む小さい有界区間であれば何でも良いが、今回は便宜的に$|\epsilon|<1$とした)。これを用いて新たな確率変数を$X_T^{N,\epsilon}:=X_T^{N}+\epsilon \tilde{B}_T,X_T^{N,\epsilon}:=X_T+\epsilon \tilde{B}_T$と定義する。


$F_m\to F (in\ L^2(\tilde{\mu}))$となるようにコンパクトな台を持つ関数列$F_m$をとる。
\begin{align}
\mathcal{E}_1(\epsilon,m):=E[F_m(X^\epsilon_T)H_T-F_m(X^{\epsilon,N}_T)H_T]\\
\mathcal{E}_2(\epsilon,m):=E[F_m(X^{\epsilon,N}_T)H_T-F_m(X^{\epsilon,N}_T)H^N_T]
\end{align}

とすると勾配誤差$F(X_T)H_T-F(X^N_T)H^N_T=lim_{m\to\infty,\epsilon\to0}(\mathcal{E}_1(\epsilon,m)+\mathcal{E}_2(\epsilon,m))$である。
\begin{align}
|\mathcal{E}_1(m)|\leq K_1(T,x)(||F_m(X^\epsilon_T)||_{L^2}+||F_m(X^{\epsilon,N}_T)||_{L^2}+\int^1_0||F_m(X^{\lambda,N,\epsilon}_T)||_{L^2}d\lambda )||1/det(\gamma_T)||^q_{L^p}\frac{T}{N}\\
|\mathcal{E}_2(m)|\leq K_2(T,x)(||F_m(X^\epsilon_T)||_{L^2}+||F_m(X^{\epsilon,N}_T)||_{L^2} )||1/det(\gamma_T)||^q_{L^p}\frac{T}{N}
\end{align}
\end{theo}


この定理を用いて上記定理を証明する。

$f,g$は$x$に対して大域的Lipsitz連続かつ$t$に対して$1/2$次 Hölder連続、さらに$F$はたかだか多項式増大である。そのため$f,g,F$から定まる定数$M(f,g,F):=sup_{\lambda,N,\epsilon} E[|F(X^{\epsilon,N,\lambda}_T)|]<\infty$を定義することができる。

定理3.7の不等式右辺に対して、$m\to\infty,\epsilon\to0$とすることで、Lebesgueの収束定理を用いて

\begin{align*}
&|F(X_T)H_T-F(X^N_T)H^N_T|\nonumber\\
&=lim_{m\to\infty}|\mathcal{E}_1(m)+\mathcal{E}_2(m)|\\
&\leq lim_{m\to\infty}(|\mathcal{E}_1(m)|+|\mathcal{E}_2(m)|)(三角不等式)\\
&=lim_{m\to\infty} K_1(T,x)(||F_m(X^\epsilon_T)||_{L^2}+||F_m(X^{\epsilon,N}_T)||_{L^2}+\int^1_0||F_m(X^{\lambda,N,\epsilon}_T)||_{L^2}d\lambda )\\
&||1/\det(\gamma_T)||^q_{L^p}\frac{T}{N}+K_1(T,x)(||F_m(X^\epsilon_T)||_{L^2}+||F_m(X^{\epsilon,N}_T)||_{L^2} )
||1/\det(\gamma_T)||^q_{L^p}\frac{T}{N}\\
&\leq (K_1(T,x)\cdot 3M(f,g,F)+K_2(T,x)\cdot 2M(f,g,F))||1/\det(\gamma_T)||^q_{L^p}\frac{T}{N}(主定理の仮定及びLebesgueの収束定理)
\end{align*}

となる。

あとは$\partial_\alpha E[F(X_T)]=E[\partial_xF(X_T)\dot{X}_T],\partial_\alpha E[F(X^N_T)]=E[\partial_xF(X^N_T)\dot{X}^N_T]$であることに注意しつつ、定理3.6の部分積分公式を用い、$K(T,x):=3K_1(T,x)+2K_2(T,x)$とすることで、主定理を得る。


\begin{cau} 4章　主定理の汎用性

主定理は最もメジャーな確率的ResNetであるStochastic Depthの連続化に対して勾配誤差の漸近性を見たが、 条件以外は一般の伊藤型確率微分方程式に連続化できる確率的ResNetに対しても言えることである。

他の連続化可能な確率的ResNet（Shakeshake modelやStochastic Depthの連続化でブラウン運動を多次元にしたものなど）に対しても、Hörmander条件さえ証明すればあとは同じである。

すなわち、$f,g$が$x$に対して大域的Lipsitz連続で$t$に対して$1/2$次 Hölder連続、かつ$F$がたかだか多項式増大であれば本章主定理と同じ不等式が言える。

\end{cau}


\subsection{輸送理論とポテンシャルの存在条件}
今回我々は確率的残差学習について、微分方程式論で解析的な考察を行ったが、それとは別に輸送理論を用いた幾何学的な考察も存在する。

この項では、その輸送理論とその応用について軽く触れ、最後にこの研究で証明できた些末な定理を述べる。

最適輸送問題の歴史は古く、始まりはMongeの定義した最適輸送問題である

\begin{defi} 最適輸送問題（古典）

$\mathbb{R}^d$上の二つの確率測度$\mu,\tau$を考える。

ここで、写像$T:\mathbb{R}^d\to\mathbb{R}^d$を、$\mu T^{-1}=\tau$となるものであるとする。この$T$を$\mu$から$\tau$への輸送する写像といい、コスト関数$c:\mathbb{R}^d\times\mathbb{R}^d\to\mathbb{R}$を定義したうえで
\begin{align}
\int_{\mathbb{R}^d}c(x,T(x))\mu(dx)
\end{align}

が最小になるような$T$の存在、そして具体的な構成を考えたい。

この問いを古典的最適輸送問題といい、解$T$を最適輸送写像、もしくは単に輸送写像と呼ぶ。

\end{defi}


古典的な最適輸送問題は輸送解析が何を問題としているかのイメージが掴みやすいが、不良設定である。そこで若干拡張した現代的な最適輸送問題がある。

\begin{defi} 最適輸送問題（現代）

$\mathbb{R}^d$上の二つの確率測度$\mu,\tau$を考える。

$\mathbb{R}^d\times \mathbb{R}^d$上の確率測度$\pi$が任意のぼれる加速集合$A$に対して、次の条件を満たすとき、$\pi$を$\mu,\tau$のカップリングであるという

\begin{align}
\pi[A\times\mathbb{R}^d]=\mu(A)\\
\pi[\mathbb{R}^d\times A]=\tau(A)
\end{align}

このようなカップリング測度全体の集合を$\Pi(\mu,\tau)$と書く。

そして
\begin{align}
argmin_{\pi\in\Pi(\mu,\tau)}\int_{\mathbb{R}^d\times\mathbb{R}^d}c(x,y)\pi(dxdy)
\end{align}
を考えることを、現代的な最適輸送問題、もしくはただ単に最適輸送問題という

\end{defi}


最適輸送問題はMongeによる提起が1708年と古いにも関わらず、この解の存在等に一定の成果が出たのは1987年と非常に新しい。


\begin{theo} 最適輸送問題の解[14]

$c(x,y)=|x-y|^2$とする。要するに距離の２乗分コストがかかると仮定する。（この仮定は応用上最も汎用性が高いと思われる）

$\mu,\tau$がともに２時モーメントが存在し、$\mu$がLebesgue測度に絶対連続なら、最適輸送問題には解が存在し

\begin{align}
\pi(\mu,\tau)=(id_{\mathbb{R}^d},\nabla \phi)_\#\mu
\end{align}

ただし$\phi$は恒等的に$\infty$でない$\mathbb{R}^d\to\mathbb{R}\cup\{\infty\}$となる凸関数である。

この$T=\nabla \phi$を最適輸送問題の解、もしくは単に最適輸送写像と呼ぶ。

\end{theo}

さらに、輸送写像の連続的な変形と、それに伴う分布の連続的な変形を考える。

\begin{defi}輸送勾配流[15]

$V(t,x):[0,T]\times\mathbb{R}^d\to\mathbb{R}$を用いて、$V_t(x):=V(t,x)$として

\begin{align}
\dot{x}_t=\nabla V_t(x_t)
\end{align}

という常微分方程式を考える。このとき、データ分布$\mu_0$に対応する密度を$p_0$と置くと、時刻$t$での密度$p_t$は


\begin{align}
p_t(x_t)|\nabla_{x_0} x_t|=p_0(x_0)
\end{align}

という等式を満たす。また$p_t$は次の偏微分方程式を満たす

\begin{align}
\partial_t p_t(x)=-\nabla\cdot [p_t(x)\nabla V_t(x)]
\end{align}

$\nabla\cdot$はダイバージェンスである。

\end{defi}

$\{\mu_t\}^T_{t=0}$は一定の条件を満たす確率測度で構成された、Wasserstein空間という無限次元のRiemannian 多様体上の測地線と見做せる。これを用いた幾何学的な解析が、DAE等に対して行われている。

ここからはこの輸送解析に対する、些細な定理を証明できたため、紹介させていただく。

決定論的なResNetは、
\begin{align}
\dot{x}_t=f(t,x_t)\\
f(t,x)=V(t)\eta(W(t)x+b_1(t))+b_2(t)
\end{align}
という常微分方程式の離散化だと言えるが、これをさらに輸送勾配流と見なす場合は、どのような$f$ならポテンシャルを持つと言え、$\dot{x}_t=\nabla_xF(t,x_t)$と書ける（最適輸送勾配流になりうる）かが重要となる。それについては次の定理を我々は証明した。



\begin{theo} ポテンシャルの存在条件

任意の$t\in[0,T]$に対して$V^T(t)=W(t)$の時、$\nabla_xF(t,x)=f(t,x)$となるスカラーポテンシャル関数$F:[0,T]\times \mathbb{R}^d\to\mathbb{R}$が存在する。


また、活性化関数$\sigma:\mathbb{R}\to\mathbb{R}$を積分して積分定数を0にした関数$\psi$を考える。当然$\psi^`=\sigma$である。$\Psi:\mathbb{R}^d\to\mathbb{R}$を$\Psi(z):=\sum^d_{i=1}\psi(z_i)$とおけば、ポテンシャルは
\begin{align}
F(t,x_t)=\Psi(W_1(t)x+b_1(t))+\langle b_2(t),x\rangle+C
\end{align}
ただし$C$は任意の定数

proof.

ポテンシャルの存在だけ証明すれば十分である。

$f$の定義域$\mathbb{R}^d$は明らかに単連結なので、ポアンカレの補題より、

\begin{align}
任意のi,j\in\{1,2,......,d\}に対して \nonumber\\
\frac{\partial f_i}{\partial x_j}=\frac{\partial f_j}{\partial x_i}
\end{align}
がポテンシャルの存在と同値である。

$y:=\eta(Wx)$として

\begin{align}
f_j(x)&=V_jy\\
&=\sum^L_{l=1} V_{j,l}y_l\\
y_l&=\sigma(W_l x)\\
&=\sigma(\sum^d_{k=0}W_{l,k} x_k)\\
\frac{\partial f_j(x)}{\partial x_i}&=\sum^L_{l=1}V_{j,l}\frac{\partial y_l}{\partial x_i}\\
&=\sum^L_{l=1}V_{j,l}W_{l,i}\sigma^{'}(\sum^d_{k=0}W_{l,k} x_k)
\end{align}

同様に右辺は
\begin{align}
\frac{\partial f_i(x)}{\partial x_j}=\sum^L_{l=1}V_{i,l}W_{l,j}\sigma^{'}(\sum^d_{k=0}W_{l,k} x_k)
\end{align}

よって$V=W^T$であればポテンシャルが存在することがわかる

\end{theo}

この定理は、輸送勾配流の定義と併せることで「輸送勾配流構成としての側面が強いタスク（ex.GAN,AE）に対しては、ResNet+転置学習で学習させるのが効率がよい」ということを示唆している。

事実、GANやAEといったタスクにおいては、$V=W^T$とする手法がそれなりに使われている。




\newpage
\section{最適化アルゴリズムとエルゴード性}

\subsection{様々な勾配法アルゴリズム}



\subsection{発展：SDEのエルゴード性と最適化アルゴリズムが非凸損失関数の大域的最適解に確率収束する条件}


\subsection{発展：（先端研究）現実的な計算時間で1epoch走らせられ、かつ非凸損失関数であっても大域的最適解に確率収束するアルゴリズム発見に向けた今後の課題}

\newpage

\section{強化学習と確率制御}
著者の今の飯の種である。
\subsection{マルコフ決定過程}



\subsection{発展：部分観測マルコフ決定過程}




\subsection{発展：分布型強化学習}


\subsection{発展：統一理論・超一般化マルコフ決定過程}
本当はこちらの定義を先に書いて、上記3定義はすべてこの特別な場合と言おうとしたが、強化学習初学者相手だといくら数学徒向けとはいえ鬼畜すぎるので最後に表記する。


\subsection{（有料版限定）発展：（先端研究）レヴィ過程に基づく連続時間強化学習}
著者の研究テーマである。

\newpage
\section{（有料版限定）：本書で用いられている数学の概説}
2→４
9.→５
4→6　アーキテクチャ、７ODEnet
11,12→８，９
15→10
14→１１
10→12
22→１３
25→１４
1→  １５
6→16
\newpage

\begin{thebibliography}{99}
  \bibitem{キー}  P. Protter, Stochastic Integration and Differential Equations, Applications of Mathematics, Second edition, Vol. 21 (Springer-Verlag, Berlin, 2005).
  \bibitem{キー}   Sho Sonoda, Isao Ishikawa, Masahiro Ikeda, Kei Hagihara, Yoshihiro Sawano, Takuo Matsubara, Noboru Murata,Integral representation of shallow neural network that attains the global minimum.arXiv:1805.07517v2,2018
    \bibitem{キー} S. Saitoh. Integral transforms, reproducing kernels and their applications. Addison Wesley Longman, 1997
     \bibitem{キー} K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In CVPR, 2016.
  \bibitem{キー} Han, D., Kim, J., Kim, J.: Deep pyramidal residual networks. In: Proc. of Computer Vision and Pattern Recognition CVPR,2017 
    \bibitem{キー} Yiping Lu, Aoxiao Zhong, Quanzheng Li, and Bin Dong. Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations. arXiv preprint, arXiv:1710.10121,2017.  
  \bibitem{キー} T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. Duvenaud, “Neural ordinary differential equations,” arXiv preprint arXiv:1806.07366, 2018.
    \bibitem{キー}  R. S. Liptser and A. N. Shiryaev, Statistics of Random Processes I: General Theory, 2nd ed. Berlin, Germany: Springer-Verlag, 2001.
  \bibitem{キー} Ioannis Karatzas,Steven Shreve,Brownian Motion and Stochastic Calculus. 2nd ed. Springer,Berlin Heidelberg New York.1998
     \bibitem{キー} Nualart, D.: Malliavin Calculus and Related Topics. (Probability and its Applications) Berlin Heidelberg New York: Springer,2000
       \bibitem{キー} Philip E Protter,Stochastic Integration and Differential Equations. Springer, New York.1990
      \bibitem{キー} Etienne Pardoux1,Shanjian Tang,Forward–backward stochastic differential equations and quasilinear parabolic PDEs. Probab. Theory Related Fields 114 123–150,1999  
       \bibitem{キー} Peter E. Kloeden,Eckhard Platen,Numerical Solution
of Stochastic Differential Equations,Springer,2011  
   \bibitem{キー} Y. Brenier, Polar factorization and monotone rearrangement of vector-valued functions, Comm. Pure Appl. Math. 44 375–417,1991
     \bibitem{キー}Sho Sonoda and Noboru Murata. Double continuum limit of deep neural networks. ICML Workshop Principled Approaches to Deep Learning, 2017
     \bibitem{キー} Gobet, E., Munos, R.: Sensitivity analysis using Ito–Malliavin calculus and martingales. Application to stochastic control problem. SIAM J. Control Optim. 43, 1676–1713,2005
\end{thebibliography}

\end{document}
